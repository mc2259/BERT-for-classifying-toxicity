# BERT-for-classifying-toxicity

It only takes one racist comment to sour an online discussion. A main area of focus is machine learning models that can identify racism in online conversations, where toxicity is defined as anything rude, disrespectful or otherwise likely to make someone leave a discussion. 
If these toxic contributions can be identified, we could have a safer, more collaborative internet. I use transformers in this personal project to give each tweet
a toxicity score. The dataset has been taken from the kaggle Jigsaw Multilingual Toxic Comment Classification challenge.
